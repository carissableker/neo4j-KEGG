{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from numpy import NaN as NaN\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\r\n"
     ]
    }
   ],
   "source": [
    "!pwd -P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths in\n",
    "reactions_file_name       = '/home/jovyan/data/KEGG_dowload/KEGG_reactions.tsv'\n",
    "compounds_file_name       = '/home/jovyan/data/KEGG_dowload/KEGG_compounds.tsv'\n",
    "glycans_file_name         = '/home/jovyan/data/KEGG_dowload/KEGG_glycans.tsv'\n",
    "\n",
    "glycans_link_name         = '/home/jovyan/data/KEGG_dowload/gl-to-cpd-api.txt'\n",
    "compounds_brite_file_name = '/home/jovyan/data/KEGG_dowload/br08001.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths out\n",
    "compound_entities_file      = '/home/jovyan/data/import/KEGG_compound_entities.tsv'\n",
    "reaction_entities_file      = '/home/jovyan/data/import/KEGG_reaction_entities.tsv'\n",
    "product_relationship_file   = '/home/jovyan/data/import/KEGG_relationship_PRODUCT.tsv'\n",
    "substrate_relationship_file = '/home/jovyan/data/import/KEGG_relationship_SUBSTRATE.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonspecific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(x):\n",
    "    return \",\".join([str(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detag(x):\n",
    "    try:\n",
    "        soup = BeautifulSoup(x, \"html5lib\")\n",
    "        return list(set([x.strip('\\\"').upper() for x in soup.text.split(\" // \")]))\n",
    "    except Exception as e:\n",
    "        return [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions = pd.read_csv(reactions_file_name, sep=\"\\t\", na_values=[\": NULL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create synonym list\n",
    "df_reactions[\"SYNONYMS\"] = [df_reactions[\"NAME\"][i].split(\"; \") if df_reactions[\"NAME\"][i] is not NaN\n",
    "                        else [df_reactions[\"ENTRY\"][i]] \n",
    "                        for i in range(df_reactions.shape[0])]\n",
    "pd.isnull(df_reactions[\"SYNONYMS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace name\n",
    "df_reactions[\"NAME\"] = df_reactions[\"SYNONYMS\"].apply(lambda x: '\"%s\"'%x[0].replace('\"', \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split enzymes\n",
    "df_reactions['ENZYME'] = df_reactions['ENZYME'].apply(lambda x: [\"%s\"%t for t in re.split(\"\\s+\", x)] \n",
    "                                                      if x is not NaN \n",
    "                                                      else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pathway ids \n",
    "df_reactions[\"PATHWAY\"] = [re.findall(r'rn[0-9]*', s) if s is not NaN \n",
    "                           else [] \n",
    "                           for s in df_reactions[\"PATHWAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double quotes for the rest\n",
    "df_reactions['EQUATION'] = df_reactions['EQUATION'].apply(lambda x: '\"%s\"'%x)\n",
    "df_reactions['DEFINITION'] = df_reactions['DEFINITION'].apply(lambda x: '\"%s\"'%x.strip().replace('\"', \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lists to strings\n",
    "df_reactions[\"PATHWAY\"] = df_reactions[\"PATHWAY\"].apply(list_to_string)\n",
    "df_reactions[\"SYNONYMS\"] = df_reactions[\"SYNONYMS\"].apply(list_to_string)\n",
    "df_reactions[\"ENZYME\"] = df_reactions[\"ENZYME\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions = df_reactions[[\"ENTRY\", \"NAME\", \"SYNONYMS\", \"DEFINITION\", \"EQUATION\", \"ENZYME\", \"PATHWAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.columns = ['ID', \n",
    "                        'NAME',\n",
    "                        'SYNONYMS',\n",
    "                        'NAME_EQUATION', \n",
    "                        'EQUATION', \n",
    "                        'EC_NUMBERS', \n",
    "                        'PATHWAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.set_index(\"ID\", drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some reactions are defined by glycans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glycan links\n",
    "f = lambda x:x.split(\":\")[1]\n",
    "df_gl_to_c = pd.read_csv(glycans_link_name, sep=\"\\t\", \n",
    "                         header=None, index_col=0, names=[\"gl\", \"compound\"], \n",
    "                         converters={0:f, 1:f})\n",
    "# remove glycans with multiple compound links (need to add seperately)\n",
    "df_gl_to_c = df_gl_to_c[~df_gl_to_c.index.duplicated(False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glycans_to_add = []\n",
    "with open(product_relationship_file, 'w') as out_product:\n",
    "    with open(substrate_relationship_file, 'w') as out_substrate:\n",
    "        out_product.write(  '%s\\t%s\\t%s\\n'%('rxnID', 'cpdID', 'STOICHIOMETRY') )\n",
    "        out_substrate.write('%s\\t%s\\t%s\\n'%('rxnID', 'cpdID', 'STOICHIOMETRY') )\n",
    "        for i, row in df_reactions.iterrows():\n",
    "            ID = row['ID']\n",
    "            eqn = row['EQUATION']\n",
    "\n",
    "            try:\n",
    "                substrates, products = eqn.strip('\"').split(' <=> ')\n",
    "            except ValueError:\n",
    "                print('Failed at reaction %s, eqn is %s'%(row['ID'], eqn))\n",
    "                break\n",
    "\n",
    "            substrate_list = []\n",
    "            product_list = []\n",
    "            stochiometry_dict = {}\n",
    "\n",
    "            pattern = '^(.*?)\\s*([a-zA-Z]{1}[\\d]+)(.*?)$'\n",
    "            for targets, direction, compound_list in [\n",
    "                (substrates, 'substrate', substrate_list), \n",
    "                (products,   'product',   product_list)]:\n",
    "\n",
    "                for t in targets.split(' + '):\n",
    "                    stoichiometry_a, target, stoichiometry_b = re.match(pattern, t).groups()\n",
    "                    if target[0] == \"G\":\n",
    "                        try:\n",
    "                            target = df_gl_to_c.loc[target][\"compound\"]\n",
    "                        except KeyError:\n",
    "                            glycans_to_add.append(target)\n",
    "\n",
    "                    compound_list.append(target)\n",
    "\n",
    "                    if stoichiometry_a: \n",
    "                        stoichiometry = stoichiometry_a.strip(\"(\").strip(\")\")\n",
    "                    elif stoichiometry_b:\n",
    "                        stoichiometry = stoichiometry_b.strip(\"(\").strip(\")\")\n",
    "                    else:\n",
    "                        stoichiometry = 1\n",
    "\n",
    "                    stochiometry_dict[target] = stoichiometry\n",
    "\n",
    "            for compound_list, file_ in ([substrate_list, out_substrate], \n",
    "                                         [product_list,   out_product]):\n",
    "                \n",
    "                for target in compound_list:\n",
    "                    stoichiometry = stochiometry_dict[target]\n",
    "                    s = '%s\\t%s\\t%s\\n'%(ID, target, stoichiometry)\n",
    "                    file_.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactions.to_csv(reaction_entities_file, encoding=\"utf-8\", quoting=3, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compound vertices\n",
    "Includes all compounds, and any glycans referenced to in reactions that were not replaced by a compound. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds = pd.read_csv(compounds_file_name, sep=\"\\t\", na_values=[\": NULL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_glycans = pd.read_csv(glycans_file_name, sep=\"\\t\", na_values=[\": NULL\"])\n",
    "df_glycans.set_index(\"ENTRY\", drop=False, inplace=True)\n",
    "df_glycans = df_glycans.loc[list(set(glycans_to_add))]\n",
    "df_glycans.columns = df_compounds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds = df_compounds.append(df_glycans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create synonym list\n",
    "df_compounds[\"SYNONYMS\"] = [df_compounds[\"NAME\"][i].split(\"; \") if df_compounds[\"NAME\"][i] is not NaN\n",
    "                            else [df_compounds[\"ENTRY\"][i]] \n",
    "                            for i in range(df_compounds.shape[0])]\n",
    "pd.isnull(df_compounds[\"SYNONYMS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace name\n",
    "df_compounds[\"NAME\"] = df_compounds[\"SYNONYMS\"].apply(lambda x: \"%s\"%x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pathway ids \n",
    "df_compounds[\"PATHWAY\"] = [re.findall(r'map[0-9]*', s) if s is not NaN \n",
    "                           else [] \n",
    "                           for s in df_compounds[\"PATHWAY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brite hierachy of compounds\n",
    "with open(compounds_brite_file_name, \"r\") as handle:\n",
    "    j = json.load(handle)\n",
    "\n",
    "def tree(k):\n",
    "    parent = re.sub('\\[.*\\]', '', k[\"name\"]).strip()\n",
    "    children = k[\"children\"]\n",
    "    for d in children:\n",
    "        child = re.sub('\\[.*\\]', '', d[\"name\"]).strip()\n",
    "        if not \"children\" in d.keys():\n",
    "            child = child.split(\" \")[0]\n",
    "            \n",
    "        parents[child].append(parent)\n",
    "        if \"children\" in d.keys():\n",
    "            tree(d)\n",
    "parents = defaultdict(list)\n",
    "tree(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peptides'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dumb peptides linking to peptides\n",
    "parents[\"Peptides\"].pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ancestors(c):\n",
    "    \n",
    "    def recursive_ancestors(c, ancestors):\n",
    "        if c in parents:\n",
    "            for p in parents[c]:\n",
    "                ancestors.append(p)\n",
    "                ancestors = recursive_ancestors(p, ancestors)\n",
    "        return ancestors\n",
    "    \n",
    "    ancestors = recursive_ancestors(c, [])\n",
    "    return ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_compounds[\"BRITE_HIERARCHY\"] = df_compounds[\"ENTRY\"].apply(get_ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all lists to strings\n",
    "df_compounds[\"PATHWAY\"] = df_compounds[\"PATHWAY\"].apply(list_to_string)\n",
    "df_compounds[\"SYNONYMS\"] = df_compounds[\"SYNONYMS\"].apply(list_to_string)\n",
    "df_compounds[\"BRITE_HIERARCHY\"] = df_compounds[\"BRITE_HIERARCHY\"].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds = df_compounds[[\"ENTRY\", \"NAME\", \"SYNONYMS\", \"FORMULA\", \"PATHWAY\", \"BRITE_HIERARCHY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compounds.columns = ['ID', \n",
    "                        'NAME', \n",
    "                        'SYNONYMS', \n",
    "                        'FORMULA', \n",
    "                        'PATHWAY', \n",
    "                        'BRITE_HIERARCHY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_compounds.to_csv(compound_entities_file, encoding=\"utf-8\", quoting=3, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
